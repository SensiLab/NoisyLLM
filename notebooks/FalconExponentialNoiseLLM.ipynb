{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/tmcn0009/anaconda3/envs/falcon_env/lib/python3.10/site-packages (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision in /home/tmcn0009/anaconda3/envs/falcon_env/lib/python3.10/site-packages (0.15.2+cu118)\n",
      "Requirement already satisfied: torchaudio in /home/tmcn0009/anaconda3/envs/falcon_env/lib/python3.10/site-packages (2.0.2+cu118)\n",
      "Requirement already satisfied: filelock in /home/tmcn0009/.local/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in /home/tmcn0009/.local/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/tmcn0009/.local/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/tmcn0009/.local/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/tmcn0009/anaconda3/envs/falcon_env/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/tmcn0009/anaconda3/envs/falcon_env/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: cmake in /home/tmcn0009/anaconda3/envs/falcon_env/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.25.0)\n",
      "Requirement already satisfied: lit in /home/tmcn0009/anaconda3/envs/falcon_env/lib/python3.10/site-packages (from triton==2.0.0->torch) (15.0.7)\n",
      "Requirement already satisfied: numpy in /home/tmcn0009/anaconda3/envs/falcon_env/lib/python3.10/site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: requests in /home/tmcn0009/anaconda3/envs/falcon_env/lib/python3.10/site-packages (from torchvision) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/tmcn0009/anaconda3/envs/falcon_env/lib/python3.10/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/tmcn0009/anaconda3/envs/falcon_env/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tmcn0009/anaconda3/envs/falcon_env/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tmcn0009/anaconda3/envs/falcon_env/lib/python3.10/site-packages (from requests->torchvision) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tmcn0009/anaconda3/envs/falcon_env/lib/python3.10/site-packages (from requests->torchvision) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tmcn0009/anaconda3/envs/falcon_env/lib/python3.10/site-packages (from requests->torchvision) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/tmcn0009/.local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "hxpPNm67GVF6",
    "outputId": "dbb852ad-92b3-406a-a05d-88d9817b7fa3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59c52362a9a487182d04d6d0afcbd21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import math\n",
    "from typing import Optional, Union, Dict, Tuple, List, Set\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"tiiuae/falcon-7b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                                             torch_dtype=torch.bfloat16,\n",
    "                                             trust_remote_code=True,\n",
    "                                             device_map=\"auto\")\n",
    "                             \n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "\n",
    "generated_text = pipeline(\n",
    "    text_inputs=\"text-generation\",\n",
    "    max_length=200,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "kqqXVGfia58S",
    "outputId": "34aaca07-5d15-49a6-cd16-747d595e7d72"
   },
   "outputs": [],
   "source": [
    "class NoiseInjector:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = next(model.parameters()).device\n",
    "        self.layer_mapping = self._create_layer_mapping()\n",
    "        self.layer_noise_stats = {}\n",
    "\n",
    "    def _create_layer_mapping(self):\n",
    "        layer_mapping = {\n",
    "            'attention': [],\n",
    "            'ffn': [],\n",
    "            'all': []\n",
    "        }\n",
    "        \n",
    "        attention_layers = []\n",
    "        for name, _ in self.model.named_modules():\n",
    "            layer_idx = None\n",
    "            for part in name.split('.'):\n",
    "                if part.isdigit():\n",
    "                    layer_idx = int(part)\n",
    "                    break\n",
    "\n",
    "            if layer_idx is not None:\n",
    "                if 'attention' in name.lower():\n",
    "                    attention_layers.append(layer_idx)\n",
    "                    layer_mapping['attention'].append(layer_idx)\n",
    "                elif any(x in name.lower() for x in ['ffn', 'mlp', 'feedforward']):\n",
    "                    layer_mapping['ffn'].append(layer_idx)\n",
    "                layer_mapping['all'].append(layer_idx)\n",
    "\n",
    "        # Ensure unique and sorted layers\n",
    "        layer_mapping['attention'] = sorted(list(set(layer_mapping['attention'])))\n",
    "        layer_mapping['ffn'] = sorted(list(set(layer_mapping['ffn'])))\n",
    "        layer_mapping['all'] = sorted(list(set(layer_mapping['all'])))\n",
    "        \n",
    "        self.num_attention_layers = len(layer_mapping['attention'])\n",
    "        if self.num_attention_layers == 0:\n",
    "            raise ValueError(\"No attention layers found in the model\")\n",
    "        \n",
    "        return layer_mapping\n",
    "\n",
    "    def prepare_inputs(self, prompt: str):\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)  # Add truncation\n",
    "        input_ids = inputs.input_ids.to(self.device)\n",
    "        attention_mask = inputs.attention_mask.to(self.device)\n",
    "        return input_ids, attention_mask\n",
    "\n",
    "    \n",
    "    def validate_config(self, config: dict) -> dict:\n",
    "        config = config.copy()\n",
    "        \n",
    "        # Validate temperature\n",
    "        if config.get('temperature', 1.0) <= 0:\n",
    "            print(\"Warning: Temperature must be positive. Setting to 1.0\")\n",
    "            config['temperature'] = 1.0\n",
    "            \n",
    "        # Validate top_p\n",
    "        if config.get('top_p', 1.0) <= 0 or config.get('top_p', 1.0) > 1:\n",
    "            print(\"Warning: top_p must be between 0 and 1. Setting to 0.9\")\n",
    "            config['top_p'] = 0.9\n",
    "            \n",
    "        # Validate noise values\n",
    "        noise_keys = ['query_noise', 'key_noise', 'value_noise', 'output_noise']\n",
    "        for key in noise_keys:\n",
    "            if key in config and config[key] < 0:\n",
    "                print(f\"Warning: {key} cannot be negative. Setting to 0\")\n",
    "                config[key] = 0.0\n",
    "                \n",
    "        return config\n",
    "    \n",
    "    def get_layer_noise_profile(self, layer_idx):\n",
    "        if layer_idx is None:\n",
    "            return 1.0\n",
    "            \n",
    "        if self.num_attention_layers is None or self.num_attention_layers == 0:\n",
    "            return 1.0\n",
    "            \n",
    "        noise_strategy = self.noise_config.get('noise_strategy', 'uniform')\n",
    "        \n",
    "        if noise_strategy == 'uniform':\n",
    "            return 1.0\n",
    "        elif noise_strategy == 'linear_decay':\n",
    "            return max(0.0, 1.0 - (layer_idx / self.num_attention_layers))\n",
    "        elif noise_strategy == 'exp_decay':\n",
    "            exp_rate = self.noise_config.get('exp_rate', -2)\n",
    "            return math.exp(exp_rate * layer_idx / max(1, self.num_attention_layers))\n",
    "        elif noise_strategy == 'first_layer_only':\n",
    "            return 1.0 if layer_idx == 0 else 0.0\n",
    "        elif noise_strategy == 'last_layer_only':\n",
    "            return 1.0 if layer_idx == (self.num_attention_layers - 1) else 0.0\n",
    "        else:\n",
    "            return 1.0\n",
    "\n",
    "    def get_dropout_layers(self,\n",
    "                         dropout_config: Dict[str, Union[float, List[int], str]]) -> Set[int]:\n",
    "        dropout_prob = dropout_config.get('dropout_prob', 0.0)\n",
    "        layer_type = dropout_config.get('layer_type', 'all')\n",
    "        specific_layers = dropout_config.get('specific_layers', None)\n",
    "        mode = dropout_config.get('mode', 'random')\n",
    "        min_layers = dropout_config.get('min_layers', 1)\n",
    "\n",
    "        if specific_layers is not None:\n",
    "            candidate_layers = specific_layers\n",
    "        else:\n",
    "            candidate_layers = self.layer_mapping[layer_type]\n",
    "\n",
    "        total_layers = len(candidate_layers)\n",
    "        max_dropouts = max(0, total_layers - min_layers)\n",
    "\n",
    "        if mode == 'random':\n",
    "            # Randomly select layers to drop based on probability\n",
    "            dropout_layers = set()\n",
    "            for layer in candidate_layers:\n",
    "                if len(dropout_layers) < max_dropouts and random.random() < dropout_prob:\n",
    "                    dropout_layers.add(layer)\n",
    "        else:  # sequential\n",
    "            # Drop layers sequentially from the top\n",
    "            num_dropouts = min(max_dropouts, int(total_layers * dropout_prob))\n",
    "            dropout_layers = set(candidate_layers[-num_dropouts:])\n",
    "\n",
    "        return dropout_layers\n",
    "    \n",
    "    def attention_forward_pre_hook(self, module, inputs):\n",
    "        # Get layer index\n",
    "        layer_idx = None\n",
    "        for part in str(module).split('.'):\n",
    "            if part.isdigit():\n",
    "                layer_idx = int(part)\n",
    "                break\n",
    "            \n",
    "        # If this layer should be dropped, return zero tensor\n",
    "        if layer_idx in self.dropout_layers:\n",
    "            zero_tensor = torch.zeros_like(inputs[0])\n",
    "            return (zero_tensor,) if isinstance(inputs, tuple) else zero_tensor\n",
    "            \n",
    "        if not inputs:\n",
    "            return inputs\n",
    "\n",
    "        hidden_states = inputs[0] if isinstance(inputs, tuple) else inputs\n",
    "        if not isinstance(hidden_states, torch.Tensor):\n",
    "            return inputs\n",
    "            \n",
    "        batch_size = hidden_states.size(0)\n",
    "        sequence_length = hidden_states.size(1)\n",
    "\n",
    "        # Get noise profile for this layer\n",
    "        noise_profile = self.get_layer_noise_profile(layer_idx)\n",
    "\n",
    "        def apply_scaled_noise(tensor, base_noise_magnitude, layer_idx):\n",
    "            if tensor is None:\n",
    "               return None\n",
    "           \n",
    "            noise = torch.randn(\n",
    "                batch_size,\n",
    "                sequence_length,\n",
    "                tensor.size(-1),\n",
    "                device=tensor.device\n",
    "                )\n",
    "            \n",
    "            # Normalize the base distribution\n",
    "            noise = noise / math.sqrt(tensor.size(-1))\n",
    "            \n",
    "            # Apply layer-specific noise magnitude\n",
    "            actual_magnitude = base_noise_magnitude * noise_profile\n",
    "            noise = noise * actual_magnitude\n",
    "            \n",
    "            # Track noise statistics for this layer\n",
    "            with torch.no_grad():\n",
    "                noise_std = noise.std().item()\n",
    "                tensor_std = tensor.std().item()\n",
    "                self.layer_noise_stats[layer_idx] = {\n",
    "                'noise_std': noise_std,\n",
    "                'tensor_std': tensor_std,\n",
    "                'ratio': noise_std / tensor_std if tensor_std != 0 else 0\n",
    "                }   \n",
    "            return tensor + noise\n",
    "\n",
    "        # Get the projection weights\n",
    "        q_proj = getattr(module, 'q_proj', None) or getattr(module, 'query_proj', None) or getattr(module, 'query', None)\n",
    "        k_proj = getattr(module, 'k_proj', None) or getattr(module, 'key_proj', None) or getattr(module, 'key', None)\n",
    "        v_proj = getattr(module, 'v_proj', None) or getattr(module, 'value_proj', None) or getattr(module, 'value', None)\n",
    "        \n",
    "        modified_inputs = list(inputs) if isinstance(inputs, tuple) else [input]\n",
    "\n",
    "        if q_proj is not None and self.noise_config.get('query_noise', 0) > 0:\n",
    "            query = F.linear(hidden_states, q_proj.weight if hasattr(q_proj, 'weight') else q_proj)\n",
    "            modified_inputs[0] = apply_scaled_noise(query, self.noise_config['query_noise'], layer_idx)\n",
    "\n",
    "        if k_proj is not None and self.noise_config.get('key_noise', 0) > 0:\n",
    "            key = F.linear(hidden_states, k_proj.weight if hasattr(k_proj, 'weight') else k_proj)\n",
    "            if len(modified_inputs) > 1:\n",
    "                modified_inputs[1] = apply_scaled_noise(key, self.noise_config['key_noise'], layer_idx)\n",
    "\n",
    "        if v_proj is not None and self.noise_config.get('value_noise', 0) > 0:\n",
    "            value = F.linear(hidden_states, v_proj.weight if hasattr(v_proj, 'weight') else v_proj)\n",
    "            if len(modified_inputs) > 2:\n",
    "                modified_inputs[2] = apply_scaled_noise(value, self.noise_config['value_noise'], layer_idx)\n",
    "\n",
    "            return inputs\n",
    "\n",
    "    def attention_forward_hook(self, module, inputs, output):\n",
    "        layer_idx = None\n",
    "        for part in str(module).split('.'):\n",
    "            if part.isdigit():\n",
    "                layer_idx = int(part)\n",
    "                break\n",
    "\n",
    "        # If this layer should be dropped, return zeros\n",
    "        if layer_idx in self.dropout_layers:\n",
    "            if isinstance(output, tuple):\n",
    "                zero_tensor = torch.zeros_like(output[0])\n",
    "                return (zero_tensor,) + output[1:]\n",
    "            return torch.zeros_like(output)\n",
    "\n",
    "        # Add noise to the attention output\n",
    "        if isinstance(output, tuple):\n",
    "            attention_output = output[0]\n",
    "        else:\n",
    "            attention_output = output\n",
    "\n",
    "        # Add output noise if specified\n",
    "        if self.noise_config.get('output_noise', 0) > 0:\n",
    "            noise = torch.randn_like(attention_output) * self.noise_config['output_noise']\n",
    "            attention_output = attention_output + noise\n",
    "\n",
    "\n",
    "        if isinstance(output, tuple):\n",
    "            return (attention_output,) + output[1:]\n",
    "        return attention_output\n",
    "\n",
    "    def generate_with_noise(self,\n",
    "                          prompt: str,\n",
    "                          noise_config: Dict[str, Union[float, Dict]],\n",
    "                          dropout_config: Dict[str, Union[float, List[int], str]] = None,\n",
    "                          max_length: int = 100,\n",
    "                          **kwargs) -> str:\n",
    "        self.noise_config = self.validate_config(noise_config)\n",
    "        self.layer_noise_stats = {}  # Reset noise statistics\n",
    "        \n",
    "        input_ids, attention_mask = self.prepare_inputs(prompt)\n",
    "        hooks = []\n",
    "\n",
    "        # Get layers to dropout if dropout_config is provided\n",
    "        self.dropout_layers = set()\n",
    "        if dropout_config is not None:\n",
    "            self.dropout_layers = self.get_dropout_layers(dropout_config)\n",
    "\n",
    "        # Register hooks for each attention layer\n",
    "        for name, module in self.model.named_modules():\n",
    "            if \"attention\" in name.lower():\n",
    "                pre_hook = module.register_forward_pre_hook(self.attention_forward_pre_hook)\n",
    "                hooks.append(pre_hook)\n",
    "                post_hook = module.register_forward_hook(self.attention_forward_hook)\n",
    "                hooks.append(post_hook)\n",
    "\n",
    "        try:\n",
    "            # Set up generation parameters\n",
    "            generation_config = {\n",
    "                'max_length': max_length,\n",
    "                'do_sample': True,\n",
    "                'pad_token_id': self.tokenizer.pad_token_id,\n",
    "                'eos_token_id': self.tokenizer.eos_token_id,\n",
    "                'top_k': noise_config.get('top_k', 50),\n",
    "                'top_p': noise_config.get('top_p', 1.0),\n",
    "                'temperature': noise_config.get('temperature', 1.0),\n",
    "            }\n",
    "\n",
    "            # Add any additional kwargs\n",
    "            generation_config.update(kwargs)\n",
    "\n",
    "            # Generate with noise injection\n",
    "            outputs = self.model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                **generation_config\n",
    "            )\n",
    "\n",
    "            # Print noise statistics if requested\n",
    "            if noise_config.get('verbose', False):\n",
    "                print(\"\\nNoise Statistics per Layer:\")\n",
    "                for layer_idx, stats in sorted(self.layer_noise_stats.items()):\n",
    "                    print(f\"Layer {layer_idx}:\")\n",
    "                    print(f\"  Noise std: {stats['noise_std']:.4f}\")\n",
    "                    print(f\"  Tensor std: {stats['tensor_std']:.4f}\")\n",
    "                    print(f\"  Noise/Tensor ratio: {stats['ratio']:.4f}\")\n",
    "\n",
    "            # Decode the output\n",
    "            return self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        finally:\n",
    "            # Clean up hooks\n",
    "            for hook in hooks:\n",
    "                hook.remove()\n",
    "                \n",
    "    def generate_text(prompt, max_length=100):\n",
    "        output = model(\n",
    "        prompt, \n",
    "        max_tokens=max_length, \n",
    "        stop=[],  # Add stop tokens if needed\n",
    "        echo=False\n",
    "    )\n",
    "        return output['choices'][0]['text']\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and tokenizer\n",
    "\n",
    "noise_injector = NoiseInjector(model, tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseInjector:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = next(model.parameters()).device\n",
    "        self.layer_mapping = self._create_layer_mapping()\n",
    "        self.layer_noise_stats = {}\n",
    "\n",
    "    def _create_layer_mapping(self):\n",
    "        layer_mapping = {\n",
    "            'attention': [],\n",
    "            'ffn': [],\n",
    "            'all': []\n",
    "        }\n",
    "        \n",
    "        attention_layers = []\n",
    "        for name, _ in self.model.named_modules():\n",
    "            layer_idx = None\n",
    "            for part in name.split('.'):\n",
    "                if part.isdigit():\n",
    "                    layer_idx = int(part)\n",
    "                    break\n",
    "\n",
    "            if layer_idx is not None:\n",
    "                if 'attention' in name.lower():\n",
    "                    attention_layers.append(layer_idx)\n",
    "                    layer_mapping['attention'].append(layer_idx)\n",
    "                elif any(x in name.lower() for x in ['ffn', 'mlp', 'feedforward']):\n",
    "                    layer_mapping['ffn'].append(layer_idx)\n",
    "                layer_mapping['all'].append(layer_idx)\n",
    "\n",
    "        # Ensure unique and sorted layers\n",
    "        layer_mapping['attention'] = sorted(list(set(layer_mapping['attention'])))\n",
    "        layer_mapping['ffn'] = sorted(list(set(layer_mapping['ffn'])))\n",
    "        layer_mapping['all'] = sorted(list(set(layer_mapping['all'])))\n",
    "        \n",
    "        self.num_attention_layers = len(layer_mapping['attention'])\n",
    "        if self.num_attention_layers == 0:\n",
    "            raise ValueError(\"No attention layers found in the model\")\n",
    "        \n",
    "        return layer_mapping\n",
    "\n",
    "    def prepare_inputs(self, prompt: str):\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
    "        input_ids = inputs.input_ids.to(self.device)\n",
    "        attention_mask = inputs.attention_mask.to(self.device)\n",
    "        return input_ids, attention_mask\n",
    "    \n",
    "    def validate_config(self, config: dict) -> dict:\n",
    "        config = config.copy()\n",
    "        \n",
    "        # Validate temperature\n",
    "        if config.get('temperature', 1.0) <= 0:\n",
    "            print(\"Warning: Temperature must be positive. Setting to 1.0\")\n",
    "            config['temperature'] = 1.0\n",
    "            \n",
    "        # Validate top_p\n",
    "        if config.get('top_p', 1.0) <= 0 or config.get('top_p', 1.0) > 1:\n",
    "            print(\"Warning: top_p must be between 0 and 1. Setting to 0.9\")\n",
    "            config['top_p'] = 0.9\n",
    "            \n",
    "        # Validate noise values\n",
    "        noise_keys = ['query_noise', 'key_noise', 'value_noise', 'output_noise']\n",
    "        for key in noise_keys:\n",
    "            if key in config and config[key] < 0:\n",
    "                print(f\"Warning: {key} cannot be negative. Setting to 0\")\n",
    "                config[key] = 0.0\n",
    "                \n",
    "        return config\n",
    "    \n",
    "    def get_layer_noise_profile(self, layer_idx):\n",
    "        if layer_idx is None:\n",
    "            return 1.0\n",
    "            \n",
    "        if self.num_attention_layers is None or self.num_attention_layers == 0:\n",
    "            return 1.0\n",
    "            \n",
    "        noise_strategy = self.noise_config.get('noise_strategy', 'uniform')\n",
    "        \n",
    "        if noise_strategy == 'uniform':\n",
    "            return 1.0\n",
    "        elif noise_strategy == 'linear_decay':\n",
    "            return max(0.0, 1.0 - (layer_idx / self.num_attention_layers))\n",
    "        elif noise_strategy == 'exp_decay':\n",
    "            exp_rate = self.noise_config.get('exp_rate', -2)\n",
    "            return math.exp(exp_rate * layer_idx / max(1, self.num_attention_layers))\n",
    "        elif noise_strategy == 'first_layer_only':\n",
    "            return 1.0 if layer_idx == 0 else 0.0\n",
    "        elif noise_strategy == 'last_layer_only':\n",
    "            return 1.0 if layer_idx == (self.num_attention_layers - 1) else 0.0\n",
    "        else:\n",
    "            return 1.0\n",
    "\n",
    "    def get_dropout_layers(self,\n",
    "        dropout_config: Dict[str, Union[float, List[int], str]]) -> Set[int]:\n",
    "        dropout_prob = dropout_config.get('dropout_prob', 0.0)\n",
    "        layer_type = dropout_config.get('layer_type', 'all')\n",
    "        specific_layers = dropout_config.get('specific_layers', None)\n",
    "        mode = dropout_config.get('mode', 'random')\n",
    "        min_layers = dropout_config.get('min_layers', 1)\n",
    "\n",
    "        if specific_layers is not None:\n",
    "            candidate_layers = specific_layers\n",
    "        else:\n",
    "            candidate_layers = self.layer_mapping[layer_type]\n",
    "\n",
    "        total_layers = len(candidate_layers)\n",
    "        max_dropouts = max(0, total_layers - min_layers)\n",
    "\n",
    "        if mode == 'random':\n",
    "            # Randomly select layers to drop based on probability\n",
    "            dropout_layers = set()\n",
    "            for layer in candidate_layers:\n",
    "                if len(dropout_layers) < max_dropouts and random.random() < dropout_prob:\n",
    "                    dropout_layers.add(layer)\n",
    "        else:  # sequential\n",
    "            # Drop layers sequentially from the top\n",
    "            num_dropouts = min(max_dropouts, int(total_layers * dropout_prob))\n",
    "            dropout_layers = set(candidate_layers[-num_dropouts:])\n",
    "\n",
    "        return dropout_layers\n",
    "    \n",
    "    def attention_forward_pre_hook(self, module, inputs):\n",
    "        # Get layer index\n",
    "        layer_idx = None\n",
    "        for part in str(module).split('.'):\n",
    "            if part.isdigit():\n",
    "                layer_idx = int(part)\n",
    "                break\n",
    "            \n",
    "        # If this layer should be dropped, return zero tensor\n",
    "        if layer_idx in self.dropout_layers:\n",
    "            zero_tensor = torch.zeros_like(inputs[0])\n",
    "            return (zero_tensor,) if isinstance(inputs, tuple) else zero_tensor\n",
    "            \n",
    "        if not inputs:\n",
    "            return inputs\n",
    "\n",
    "        hidden_states = inputs[0] if isinstance(inputs, tuple) else inputs\n",
    "        if not isinstance(hidden_states, torch.Tensor):\n",
    "            return inputs\n",
    "            \n",
    "        batch_size = hidden_states.size(0)\n",
    "        sequence_length = hidden_states.size(1)\n",
    "\n",
    "        # Get noise profile for this layer\n",
    "        noise_profile = self.get_layer_noise_profile(layer_idx)\n",
    "\n",
    "        def apply_scaled_noise(tensor, base_noise_magnitude, layer_idx):\n",
    "            if tensor is None:\n",
    "               return None\n",
    "           \n",
    "            noise = torch.randn(\n",
    "                batch_size,\n",
    "                sequence_length,\n",
    "                tensor.size(-1),\n",
    "                device=tensor.device\n",
    "                )\n",
    "            \n",
    "            # Normalize the base distribution\n",
    "            noise = noise / math.sqrt(tensor.size(-1))\n",
    "            \n",
    "            # Apply layer-specific noise magnitude\n",
    "            actual_magnitude = base_noise_magnitude * noise_profile\n",
    "            noise = noise * actual_magnitude\n",
    "            \n",
    "            # Track noise statistics for this layer\n",
    "            with torch.no_grad():\n",
    "                noise_std = noise.std().item()\n",
    "                tensor_std = tensor.std().item()\n",
    "                self.layer_noise_stats[layer_idx] = {\n",
    "                'noise_std': noise_std,\n",
    "                'tensor_std': tensor_std,\n",
    "                'ratio': noise_std / tensor_std if tensor_std != 0 else 0\n",
    "                }   \n",
    "            return tensor + noise\n",
    "\n",
    "        # Get the projection weights\n",
    "        q_proj = getattr(module, 'q_proj', None) or getattr(module, 'query_proj', None) or getattr(module, 'query', None)\n",
    "        k_proj = getattr(module, 'k_proj', None) or getattr(module, 'key_proj', None) or getattr(module, 'key', None)\n",
    "        v_proj = getattr(module, 'v_proj', None) or getattr(module, 'value_proj', None) or getattr(module, 'value', None)\n",
    "        \n",
    "        modified_inputs = list(inputs) if isinstance(inputs, tuple) else [input]\n",
    "\n",
    "        if q_proj is not None and self.noise_config.get('query_noise', 0) > 0:\n",
    "            query = F.linear(hidden_states, q_proj.weight if hasattr(q_proj, 'weight') else q_proj)\n",
    "            modified_inputs[0] = apply_scaled_noise(query, self.noise_config['query_noise'], layer_idx)\n",
    "\n",
    "        if k_proj is not None and self.noise_config.get('key_noise', 0) > 0:\n",
    "            key = F.linear(hidden_states, k_proj.weight if hasattr(k_proj, 'weight') else k_proj)\n",
    "            if len(modified_inputs) > 1:\n",
    "                modified_inputs[1] = apply_scaled_noise(key, self.noise_config['key_noise'], layer_idx)\n",
    "\n",
    "        if v_proj is not None and self.noise_config.get('value_noise', 0) > 0:\n",
    "            value = F.linear(hidden_states, v_proj.weight if hasattr(v_proj, 'weight') else v_proj)\n",
    "            if len(modified_inputs) > 2:\n",
    "                modified_inputs[2] = apply_scaled_noise(value, self.noise_config['value_noise'], layer_idx)\n",
    "\n",
    "            return inputs\n",
    "\n",
    "    def attention_forward_hook(self, module, inputs, output):\n",
    "        layer_idx = None\n",
    "        for part in str(module).split('.'):\n",
    "            if part.isdigit():\n",
    "                layer_idx = int(part)\n",
    "                break\n",
    "\n",
    "        # If this layer should be dropped, return zeros\n",
    "        if layer_idx in self.dropout_layers:\n",
    "            if isinstance(output, tuple):\n",
    "                zero_tensor = torch.zeros_like(output[0])\n",
    "                return (zero_tensor,) + output[1:]\n",
    "            return torch.zeros_like(output)\n",
    "\n",
    "        # Add noise to the attention output\n",
    "        if isinstance(output, tuple):\n",
    "            attention_output = output[0]\n",
    "        else:\n",
    "            attention_output = output\n",
    "\n",
    "        # Add output noise if specified\n",
    "        if self.noise_config.get('output_noise', 0) > 0:\n",
    "            noise = torch.randn_like(attention_output) * self.noise_config['output_noise']\n",
    "            attention_output = attention_output + noise\n",
    "\n",
    "\n",
    "        if isinstance(output, tuple):\n",
    "            return (attention_output,) + output[1:]\n",
    "        return attention_output\n",
    "    \n",
    "    def markov_chain_noise(self, x, markov_config):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        x (tensor): Current state\n",
    "        P (tensor): Transition probability matrix\n",
    "        xt_prev (tensor, optional): Previous state\n",
    "        \n",
    "        Returns:\n",
    "        tensor: Noisy state after Markov Chain process\n",
    "        \"\"\"\n",
    "        transition_matrix_type = markov_config.get('transition_matrix_type', 'random')\n",
    "        max_iterations = markov_config.get('max_iterations', 10)\n",
    "        noise_scale = markov_config.get('noise_scale', 0.1)\n",
    "        custom_matrix = markov_config.get('custom_matrix', None)\n",
    "\n",
    "        # Generate or load transition probability matrix\n",
    "        if transition_matrix_type == 'random':\n",
    "            P = torch.rand((x.shape[1], x.shape[1]))\n",
    "            # Normalize to make it a valid transition matrix\n",
    "            P = P / P.sum(dim=1, keepdim=True)\n",
    "        elif transition_matrix_type == 'identity':\n",
    "            P = torch.eye(x.shape[1])\n",
    "        elif transition_matrix_type == 'custom':\n",
    "            if custom_matrix is None:\n",
    "                raise ValueError(\"Custom transition matrix must be provided\")\n",
    "            P = custom_matrix\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid transition matrix type: {transition_matrix_type}\")\n",
    "\n",
    "        # Ensure P is on the same device as x\n",
    "        P = P.to(x.device)\n",
    "\n",
    "        # Initial state\n",
    "        xt = x.clone()\n",
    "        xt_prev = None\n",
    "        \n",
    "        # Markov Chain iterations\n",
    "        for _ in range(max_iterations):\n",
    "            # Transition\n",
    "            xt = torch.mm(xt.float(), P.float())\n",
    "            \n",
    "            # Noisy step\n",
    "            if xt_prev is not None:\n",
    "                # Calculate noise\n",
    "                delta = xt - xt_prev\n",
    "                noise = torch.randn_like(delta) * noise_scale\n",
    "                \n",
    "                # Apply noisy step\n",
    "                xt = xt + noise\n",
    "            \n",
    "            # Update previous state\n",
    "            xt_prev = xt\n",
    "        \n",
    "        return xt\n",
    "\n",
    "    def generate_with_noise(self,\n",
    "                          prompt: str,\n",
    "                          noise_config: Dict[str, Union[float, Dict]],\n",
    "                          dropout_config: Dict[str, Union[float, List[int], str]] = None,\n",
    "                          max_length: int = 100,\n",
    "                          **kwargs) -> str:\n",
    "        self.noise_config = self.validate_config(noise_config)\n",
    "        self.layer_noise_stats = {}  # Reset noise statistics\n",
    "        \n",
    "        input_ids, attention_mask = self.prepare_inputs(prompt)\n",
    "        hooks = []\n",
    "        \n",
    "     #markov_noise_chain\n",
    "        markov_config = noise_config.get('markov_chain', {\n",
    "        'enabled': False,\n",
    "        'transition_matrix_type': 'random',  # or 'identity', 'custom'\n",
    "        'max_iterations': 10\n",
    "        })\n",
    "        \n",
    "        # If Markov Chain noise is enabled\n",
    "        if markov_config.get('enabled', False):\n",
    "           noisy_input_ids = self.markov_chain_noise(input_ids.float(), markov_config).long()\n",
    "           input_ids = noisy_input_ids\n",
    "\n",
    "\n",
    "        # Get layers to dropout if dropout_config is provided\n",
    "        self.dropout_layers = set()\n",
    "        if dropout_config is not None:\n",
    "            self.dropout_layers = self.get_dropout_layers(dropout_config)\n",
    "\n",
    "        # Register hooks for each attention layer\n",
    "        for name, module in self.model.named_modules():\n",
    "            if \"attention\" in name.lower():\n",
    "                pre_hook = module.register_forward_pre_hook(self.attention_forward_pre_hook)\n",
    "                hooks.append(pre_hook)\n",
    "                post_hook = module.register_forward_hook(self.attention_forward_hook)\n",
    "                hooks.append(post_hook)\n",
    "\n",
    "        try:\n",
    "            # Set up generation parameters\n",
    "            generation_config = {\n",
    "                'max_length': max_length,\n",
    "                'do_sample': True,\n",
    "                'pad_token_id': self.tokenizer.pad_token_id,\n",
    "                'eos_token_id': self.tokenizer.eos_token_id,\n",
    "                'top_k': noise_config.get('top_k', 50),\n",
    "                'top_p': noise_config.get('top_p', 1.0),\n",
    "                'temperature': noise_config.get('temperature', 1.0),\n",
    "            }\n",
    "\n",
    "            # Add any additional kwargs\n",
    "            generation_config.update(kwargs)\n",
    "\n",
    "            # Generate with noise injection\n",
    "            outputs = self.model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                **generation_config\n",
    "            )\n",
    "           \n",
    "            \n",
    "            # Print noise statistics if requested\n",
    "            if noise_config.get('verbose', False):\n",
    "                print(\"\\nNoise Statistics per Layer:\")\n",
    "                for layer_idx, stats in sorted(self.layer_noise_stats.items()):\n",
    "                    print(f\"Layer {layer_idx}:\")\n",
    "                    print(f\"  Noise std: {stats['noise_std']:.4f}\")\n",
    "                    print(f\"  Tensor std: {stats['tensor_std']:.4f}\")\n",
    "                    print(f\"  Noise/Tensor ratio: {stats['ratio']:.4f}\")\n",
    "\n",
    "            # Decode the output\n",
    "            return self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        finally:\n",
    "            # Clean up hooks\n",
    "            for hook in hooks:\n",
    "                hook.remove()\n",
    "                \n",
    "    def generate_text(prompt, max_length=100):\n",
    "        output = model(\n",
    "        prompt, \n",
    "        max_tokens=max_length, \n",
    "        stop=[],  # Add stop tokens if needed\n",
    "        echo=False\n",
    "    )\n",
    "        return output['choices'][0]['text']\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sCblylE7kt3v",
    "outputId": "6fd20e95-57b0-4503-a799-7e6ad3b78679"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sad poem - by: Anonymous\n",
      "I'm not sure if I'm in love with you\n",
      "Or if I'm just in love with the idea of you\n",
      "I'm not sure if I'm in love with you\n",
      "Or if I'm just in love with the idea of you\n",
      "I'm not sure if I'm in love with you\n",
      "Or if I'm just in love with the idea of you\n",
      "I'm not sure if I'\n"
     ]
    }
   ],
   "source": [
    "noise_injector = NoiseInjector(model, tokenizer)\n",
    "\n",
    "noise_config = {\n",
    "    'query_noise':0.0,\n",
    "    'key_noise': 0.0,\n",
    "    'value_noise': 0.0,\n",
    "    'output_noise': 0.0, \n",
    "    'noise_strategy': 'uniform', # 'exp_increase' 'uniform', 'exp_decay', 'first_layer_only', 'last_layer_only'\n",
    "    'exp_rate': 1.0,  # Controls rate of exponential change in noise \n",
    "    \n",
    "    'temperature': 0.1,  #temperature must be higher than 0.0\n",
    "    'top_k': 0,  #\n",
    "    'top_p': 1.0, # Disable top-p sampling = 1.0\n",
    "    'verbose': False, \n",
    "    \n",
    "    'markov_chain': {\n",
    "        'enabled': True,\n",
    "        'transition_matrix_type': 'identity',  # or 'identity', 'custom'\n",
    "        'max_iterations': 1, #minimum 1, no max\n",
    "        'noise_scale': 0.0001,  # Adjust the scale of noise. 0.0 to 1.0 (very sensitive)\n",
    "        'custom_matrix': None,   #(random, identity, custom) must be a square matrix\n",
    "    }  \n",
    "}\n",
    "\n",
    "\n",
    "# Configure dropout parameters\n",
    "dropout_config = {\n",
    "    'dropout_prob': 0.0,        # Probability of dropping a layer\n",
    "    'layer_type': 'all',        # FFN, attention, all\n",
    "    'mode': 'random',          # Dropout mode ('random' or 'sequential')\n",
    "    'min_layers': 1,           # Minimum number of layers to keep\n",
    "    'specific_layers': []    # Optional: To use specific layers for dropout: Set specific_layers=[0, 2, 4] in dropout_config\n",
    "}\n",
    "\n",
    "'''\n",
    "#Hyperparameter\tValue\t as a reference for futuire changes\n",
    "Layers\t        32\t\n",
    "d_model\t        4544\t    Increased to compensate for multiquery\n",
    "head_dim\t    64\t        Reduced to optimise for FlashAttention\n",
    "Vocabulary\t    65024\t\n",
    "Sequence length\t2048\t\n",
    "'''\n",
    "\n",
    "#To only use noise: Omit the dropout_config parameter\n",
    "# Generate text with both noise and dropout use following\n",
    "generated_text = noise_injector.generate_with_noise(\n",
    "    prompt=\"sad poem\",\n",
    "    noise_config=noise_config,\n",
    "    dropout_config=dropout_config,\n",
    "    max_length=100\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "falcon_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
